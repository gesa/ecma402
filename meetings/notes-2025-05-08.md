# 2025-05-08 ECMA-402 Meeting

## Logistics

### Attendees

- Shane Carr - Google i18n (SFC), Co-Moderator
- Ujjwal Sharma - Igalia (USA), Co-Moderator
- Jesse Alama - Igalia (JMN)
- Henri Sivonen - Mozilla (HJS)
- Daniel Minor - Mozilla (DLM)
- Eemeli Aro - Mozilla (EAO)
- Richard Gibson - OpenJS Foundation (RGN)
- Yusuke Suzuki - Apple (YSZ)

### Standing items

- [Discussion Board](https://github.com/tc39/ecma402/projects/2)
- [Status Wiki](https://github.com/tc39/ecma402/wiki/Proposal-and-PR-Progress-Tracking) -- please update!
- [Abbreviations](https://github.com/tc39/notes/blob/master/delegates.txt)
- [MDN Tracking](https://github.com/tc39/ecma402-mdn)
- [Meeting Calendar](https://calendar.google.com/calendar/embed?src=unicode.org_nubvqveeeol570uuu7kri513vc%40group.calendar.google.com)
- [Matrix](https://matrix.to/#/#tc39-ecma402:matrix.org)

## Status Updates

### Updates from the Editors

\[USA presents\]

USA: Got a bugfix done, included in 2025 edition. Ladybird browser has helped a lot. A markup change about how we lay out the doc. Editorial change marked default locale as a fingerprinting vector. Open items: adding naming conventions. We have something blocked on ecmarkup, but we should be able to get this in soon.Simplify NumberFormat is also open, needs more reviews.

SFC: Most are ES2025 issues. OR are these ES2026?

USA:  Most are already ES2025. The open ones aren’t planned for ES2025. Let us know if any should make the cut. None seems urgent.

SFC: Default fingerprinting got in, nice.

USA: Oops. that one is not on the branch. It’s not on the branch. This is an editorial thing, so there shouldn’t be controversy outside this group about the change. But there was a change in 262, so I don’t see why we can’t do it in 2025 if we agree here.

SFC: Have we started the opt-out period?

USA: Yes. I asked JHD if that changes anything, he said no. It’s on us. Given the precedent from 262, we can probably get it into 2025. PRobably an aesthetic decision.

SFC: Default locale is definitely not without controversy, since it took so long to agree. If people have comments, they should come out of the woods.

USA: Comments might come later.

SFC: OK keep on main branch. RGN do you have updates?

RGN: No.

### Updates from the MessageFormat Working Group

EAO: SFC has been actively participating there. We haven’t changed much but we have discussed a lot. The most significant thing is that we’re actively pursuing a recommendation from SFC for Date Time Formatting in MF not following the current style of options currently in 402 and to try and see if we can see a kind of semantic skeleton or field approach that’s currently used in ICU4X since it’s a different style of supplying the date time formatting options and how you may restrict the ability to do “silly things” as you could at the moment. Nonsensical options are exactly that but tt does have a cost in terms of payload in terms of what’s required to solve this. Another question is percent formatting. We took out the percent style of the number formatter. The input value is multiplied by 100 before formatting and also in JS right now you may do style=unit and unit=percent and then format a number to get a string that looks like a similar result but without multiplying with a 100. The current language in the spec mirrors the language from the JS API and we’re considering if we should have a custom percent formatter or if we should do a possible math operator to do scaling. We’re discussing all of this.

SFC: Those are the highlights. Impact here is thinking how the changes affect the spec text and polyfill. Skeletons e.g. aren’t part of 402. It’s a good departure, but it is a departure from the Intl API. Semantics skeletons are something on top of 402, requires glue code.

USA: Is there any appetite to add semantic skeletons to Intl.DTF?

SFC: I think that's a  good question. I think a five year plan would be to do it, for a two year plan, let’s do a JS polyfill to explore the space first. This is something that goes into the ergonomics of Intl and doesn’t have any additional data cost? It should eventually even allow browsers to cut down on data size if they stick with semantic skeletons. The argument for MF having semantic skeletons is that since it’s a new thing but it might not be as useful to go back and update all the old code instead. Therefore I prefer this to be a wrapper above Intl.DTF and it could be done in a hundred lines or so.

EAO: 2 things. One: for MF, if we do semantics skeleton structure, will the implementation include the majority of that for the polyfill to work? Second, for DTF, we are already in a position to give a formatter style options or field options. Adding a conflicting 3rd alternative style, then you don’t get the field options.

USA: More options make things confusing. The DTF are the opposite of the options-bag approach. Provides developer less control. But the other makes it possible to make nonsense strings. DTF should be a kind of middle ground. So as we check the boxes of the Intl scheme, we experiment in userland or higher-level abstractions in packages or polyfills. Use that to do some research: is an API worth it? Does it improve ergonomics? At the moment users have all the options without ensuring that we produce a human-readable string.

FYT: Quick question: does the current MessageFormat support formatting a list? The way do it in the ListFormat constructor in Intl?

EAO: Not yet. We add support for that in a future CLDR release. 48, 49, 50. Later this year or next year.

### Updates from Implementers

https://github.com/tc39/ecma402/wiki/Proposal-and-PR-Progress-Tracking

FYT: Didn’t touch anything. One of the issues depends on the Chrome team to pick up the newest ICU.

YSZ: No update this month from JSC.

DLM: Same for spidermonkey.

SFC: Most of these could use tests. I don’t see a lot of tick boxes for JSC. YSZ, can you take a look?

YSZ: Yes.

USA: I was taking a look for some of these in bug trackers. I could use some help. If anyone has anything more convenient, I can update it. The test strategy sounds good.

USA: One comment: version numbers. Given the test approach, one could use eshost to find out which normative PRs are supported in each of the engines. Version is the hard part. Does this group use that information?

SFC: We don’t require it. Only half have a version. I’ve referred to the version before in some cases. If easy to get, sure. Once the version is 6+ months old, utility of that information goes down. It’s best effort. More important to have a checkbox.

USA: Sounds good. We should be able to add check boxes.
### Updates from the W3C i18n Group

EAO: the practical reality is that both BAN and I have not been able to attend these meetings. I have conflicts. It’s quite rare for that group to cover content that is relevant to us. I have not tried to rearrange my own schedule to attend these.

SFC: It’s valuable for us to have a liaison between the two groups if someone would like to volunteer that would be nice. I would try to do it myself a few times until BAN returns.

## Proposals and Discussion Topics

https://github.com/tc39/ecma402/projects/2


### Normative: Added note about sets of locales for web browser implementations needing to not change as a result of user behaviour #780

https://github.com/tc39/ecma402/pull/780

DLM: I ran the text with the privacy folks from SpiderMonkey

EAO: One thing: I haven’t written it down yet but it came up with the discussion between SFC, BAN and me at the in-person TG2 meeting last fall. The client or browser is already revealing a bunch of supported locales to the server effectively via Accept-Languages. There was a proposal to have a sort of dialog API which would reveal at most two locales but I would contend that in the vast majority of cases in a browser we end up on a page where we have already asked for contents in some locales which all parties know at some point is the default locale. For the Intl APIs we might use a locale on this page the vast majority of those ought to use that locale. There is an opportunity to prioritize support for a subset of all locales that the browser depends about that depends on the user’s explicit or implicit choice based on the Accept-Languages value .That’s one of the only places where we might be able to build into a browser the ability to dynamically update locale data. This text would limit our ability to do that. There is a possibility that we might not want to burn that bridge. The set of those locales should include such a user-preferred locale. This came up just today and the text itself leaves some space for the possibility and perhaps it’s not even doable in the current state of ICU. Just pointing out this legitimate concern about this direction.

SFC: The currently proposed text here states the web reality and also states the principles that we rely on to load locales dynamically which is why I like the current text since it keeps the door open for us while it lays down the current restrictions we already adhere to. Essentially we should define where the goalposts are so we could actually develop equitable solutions. Until this PR we don’t state anywhere that the ECMA-402 APIs cannot or should not serve as a fingerprinting vector. I like it being a net positive while still allowing us to explore that idea eventually.

### Intl Keep Trailing Zeros

https://github.com/eemeli/proposal-intl-keep-trailing-zeros

SFC: Thanks for championing this change. This is something I’ve kind of wanted to see but I didn’t work too much in this direction previously so I’m glad you’re working on it. It’s a change that sort of evolves from my previous change to expand the precision of numbers in these APIs. There is some evidence that this kind of changes are web compatible. Once we have spec text for this, the way I’d like the spec to look like would be to expand IntlMV to include trailing zeroes. And we use this value when the options for precision aren’t changed. They would take precedence over the value from the string.

EAO: Not exactly how I perceive this. The value being formatted would have its own fractional digits and we don’t include any trailing zeroes here but moving forwards we’d include them. With this change if you call NF with minFractionalDigits 0 and you format 1.0 you’d get 1.0 out but the idea would not be to change any existing default behavior. If you format 1.23456 the output by default would just include 3 fractional digits. But of course if you want to format more fractional digits then you can use options to set exactly that.

SFC: Thanks for the clarification, it’s a good example. If a number currently has trailing digits based on the rounding behavior we might be able to keep that. I want to think forward in terms of how the future behavior of formatting a decimal would be and how it affects that. In this case we’re building a common building block for formatting decimals which is nice and productive. I consider this largely a bugfix, we continue to get issues about this in 402. Also don’t think it necessarily directly impacts the decisions that get made in the decimal/amount proposals. I support this for Stage 1 and hope others do too.

EAO: The intent is for the changes to be able to format any numerical value type with trailing zeroes as well.

### Normative: Update String toLocale{Lower,Upper}Case to ResolveLocale with best-fit matching #956

https://github.com/tc39/ecma402/pull/956

RGN: Rather than have restricted behavior for toLocaleLower/Upper case, use the collator and how it’s specified. A few edge cases where the ideal behavior would benefit from that. [looks at issue] Dotted versus dotless lower i with various Turkic languages. This specifies a set of languages, some known, some unknown. We want behavior that works with collator. If you have an uppercase dotless I and toLowerCase, passing in an array where the 1st element is unknown, 2nd element is Turkish, fall through the unknown and end up a dotless lower i. Other cases: when does it triggerthe default locale vs. when does continue through the list. An initial construction of the locale list, where some information is known, then ges compared with the available locales list. As well as guidance for implementation.

HJS: Last time, we talked about the difference here compared with Intl APIs generally. This data isn’t CLDR-backed. Backed by a human-readable remaks in Unicode. That file lists 3 languages which are special cases, but no list of other languages which are known to map to the base case. Spec text assumes there exists a partition to 3: known to have a base case, known to have special case, and unknown. But we don’t really have a distinction between unknown and base case. This supposes a data situation which is not there. Not in Unicode, not in CLDR, not in any known implementation. Order of magnifture of developing this data is: which Turkic language are special cases and which not? Better case forward would be to research taht, then file that with Unicode SpecialCasing.txt . If this lands as written, we move further from implementation and data reality. The PR makes sense in theory, if there really were such data, but we don’t have this distinction. The PR confuses things. Effort involved would be better used tow rok with Unicode.

RGN: One comment, regardless of changes in the character database it  needs correction irrespectively.

HJS: Not necessarily. We could decide that the API design is faulty. You could say API doesn't match reality. Looking only at the 1st element of the list, makes sense given the available data sources. This makes sense. We know the reality is weird. Should we force the API make sense, i.e. work wth a list?

SFC: We last discussed this in Feb, one observation we made was that en doesn’t have any tailorings so it’s technically not a valid locale so technically you would have turkish behavior without tailorings.

RGN: Not correct. Current spec text makes an locale list. With at least one case-mapping translation.

SFC: The problem with available locales then is that the set of locales we have data for this feature is going to be much larger in principle.

RGN: In practice, available locale list is equivalent to all locales known to the implementation.

HJS: basically since the known locale list tends to come from Date Time formatting then that’s the largest data set in CLDR the known set of locales, that’s been vetted for specialCases.txt then if a locale has non-default behavior then specialcases.txt would already take that into account. It might be a logical leap but it might hold in practice.

RGN: Everything required by this is required by collator, which accepts a list of locales, and requires resolving to one of them.

HJS: That’s different, data-wise. In ICU4C we have “english is attested to fall back to root”. Different from “english is unknown, different from root”. Same for French, Italian, etc. But not data for “english has default case behavior”.

RGN: We need that.

HJS: We have that for collator, but not for case mapping. Different data story. Talk about English: we have no data that English has default case behavior. We have data that English uses the root collation. That data exists in ICU4C. I don’t know about CLDR. I think it exists there. CLDR has data that says that a bunch of languages are explicitly attested to use the root. Unicode doesn’t have that.

RGN: That’s covered by the note in the PR. The set of languages that have locale-sensitive case transformation is very small. “Known” means that we’re going apply the standard case-insensitive translation. We have to provide some output.

HJS: Capital I, then map to “tr”. Capital I, toLocaleLowercase(“tt”, “tr”). How can implementations decide what should happen in the “en” case and the [“tt”, “tr”] case?

RGN: Every implementation supports English.

HJS: How do we know that (for case mapping)?

RGN: That works in all imple,mentations.

HJS: The logic is “it’s not Lithuaniant, etc., so default”.

RGN: Are you asking about spec or implementation?

HJS: Asking: after this lands, what should implementations do in thet [“tt”, “tr”] case?

RGN: I assume there’s a small list of languages subject to special treatment. It must include Turkish, Azeri, and Lithuanian. Whether it supports Tatar is different. So it should be dotless i.

HJS: A list of english and turkish, and a list of tartar and turkis. Do we expect these two lists to result in different behavior, and if so, how?

RGN: different behavior. Mechanism: implementation has a defined list of supported languages for this purpose. Every implementation ought to use the same as what they use for intl collator.

HJS: Implementations put something in front of ICU4C/ICU4X so instead of using the backing library’s case mapping, they consult a collator? Nothing in the PR says that this is tied to collation data.

RGN: IT’s not tied to collation data in the spec.

HJS: How do we deal with this secret?

RGN: It’s not secret, there’s how you implement it. All language tags, we have a case mapping. Not a secret.

HJS: But we don’t have the data for case mapping. We do have the data for collations. We should treat the availability of collations as case mapping.

RGN: Implementation defined known locales for case mapping. No change is required. This is ILD. [“en”, “tr”] is different than [“zz”, “tr”].

HJS: Even if someone research Tatar and figured out it should act like Turkish in some context, to find out all turkish-like languages, then that’s more likely to help with interoperable behavior.

SFC: My feeling: I agree with HJS that this list of which locales have “good” case mapping data, where “good” is some ILD definition, is strange. We have to hope that this works, trusting that Firefox etc. get the same data. I agree with RGN on the principle that, if we have the data, we should do fallbacks. It allows people to write [“tt”, “tr”] one way and it should work. Not clear to me that there’s a good way. Is anyone going to implement this? No test262 for this. Test262 test for Klingon and then “tr”.

RGN: “zzz” instead of Klingon, but yeah, that’s the test.

SFC: I see case mapping as well as collation and segmentation in the same bucket: there’s available locales and then there’s content locales and the set of content locales is fundamentally different from formatting locales and available locales.I would generally assume we would use the same mechanism here as in Collator and Segmenter since we’re talking about content locales.

RGN: I’ve asserted that a good proxy, implementation strategy, for that step is correspondence with intl.collator. Given that we have some ignorance here, is there reason to believe that’s not a good strategy?

HJS: I would expect that it is more likely for the default case mapping behavior to (for a random language) to be correct than there to be explicit collation data for the language. There is a very large set of languages in the world for which the direct case mapping behavior works but it doesn’t have collation tailorings. We know Lithuanian Azerbaijani and Turkish are special cases and everything else is “usual”. If you’re writing the fallback you already know you can have the Turkish behavior but you want to use the other language for aesthetic reasons like using Tatar. If we filter this way we’d move a whole lot of languages in the unknown bucket whereas treating them in the default “no tailorings” case would be better. Researching the set of languages other than Azerbaijani or Tatar would be way more useful than this algorithm.

RGN: My position is that those are independent. Even updates to special-casing, this change is warranted.

HJS: What would this do? Test case that “zzz” must be skipped over. Lots of work for implementors. But to what end? We want to be able to say Tartar to get Turkish behavior instead of just saying Turkish. Someone who wants Turkish but doesn’t want to say that can get that behavior. That constituency can hold on to their own language, but allowing Turkish anyway. Instead of that, we could just do research on what the Turkish-like language is more interesting. We would say the fact that this can take a list is a design mistake and move on.

SFC: Assuming we can somewhat clear on …. It definitely seems like a simple spec bug. We normally have a locale fallback list and we’re not applying the locale fallback list here. It’s also, to HJS’ point of who is actually going to use this, this argument doesn’t apply to fixing spec bugs. It might work for prioritizing the fix itself it can be an argument about the motivation behind changes. If the mozilla position is that the motivation behind the change is weak. I would like to be more clear about the argument we are making. We should at least agree that it’s a spec bug. Then we can discuss if we can actually put in the time to fix it. I would encourage someone to put the time into this research if they’d like to.

HJS: Two points to break the circle. W3C has a doc called web design principles. Point 1.1: put user needs first (prioritize constituencies). Yes, there’s a spec bug: this takes a list ot locales. The bug isn’t how we move down the list. But fixing the bug so that it matches another API is spec purity. This is waste of time for UA implementors. Need to make “zzz” test cases. Useless waste of time. Doesn’t help web page authors or users, either. Three behaviors: default (no need to do anything there). Other cases: we have something other than Lithuianisn, but you want the Lithuanian behavior. Other case: there exists a handful of languages that are supposed to be like Turkish or Azerbajani, but not attested. The way that works today is to put turkish as the 1st and only argument in the list. “Why would I have to declare this other big language instead of my minority language?” But to have to add turkish anyway doesn’t help. Each time we talk about it we would be better servign these users by doing research and adding it to Unicode special-casings. If we don’t web devels to say “tr” if they want Turkish, we don’t solve the problem.

SFC: Thanks. My hope is that we can see this as a bug that impacts users of the web. If there are cases where [tartar,turkish] might match what’s going on for them, then we should support that. HJS says develops who specify this list. In most cases the list is coming from a different source. If it’s not accurate, let’s clarify that now, but it’s not a purity concern.

RGN: I was going to bring up that set of principles. I think the fundamental disagreement is whether this reflects an improvement for users or not. WE agree it’s an improvement on the spec. We agree that it’s a burgen of some magnitude for implementors. So following the document, we have to understand whether there’s impact on users. But SFC is right: I see it as a problem in the spec, and I want to fix it. I don’t know how big the fix will be. If the consensus is that current suers are fine, everyone specifies “tr”, then strict  adherence to the document rejects this. That’s not my position, but that’s logical.

EAO: MDN docs on toLocaleLower/UpperCase say “this takes an array but you only look at the 1st entry”. So let’s not introduce a novel sort of locale fallback behavior for this particular thing. Stick to what’s there currently. Let’s get the right results by fixing the data at the sourc rather than allowing for a 3 way split. I’m with HJS on this.

SFC: Path forward: task on improving segmenter support locales, still in progress. If we make this easier to implem,ent…we don’t have this list. We’re asking implementors to implement something that doesn’t make a lot of sense. So if we put some time in on the unicode side, we make things easier to implement and the change will have a lower user impact for Azeri user. I think the way the spec is broken is relatively minor in the grand scheme of things. I think we can do that, but let’s work more on the unicode side first.

USA: I raised my hand while EAO was speaking. I wanted to agree, but I think I misunderstood. On the topic – leaving aside case mapping, thinking more in terms of API design – it’s more of a trap/footgun for uses to specify a list of locales but have different behavior from what the user would expefct. That part translates to better UX. User = developer here. Easier for them to reason about it if it behaves like other Intl APIs.

RGN: In conclusion, it seems this isn’t worth further discussion unless there are changes made to make the available data more easily available. I’m happy to have the PR open in a tabled state we could also close it. If there are changes in ICU we could change it.

HJS: Prefer to close.

SFC: Or mark it as a draft, prevents it from up on the agenda.

RGN: will mark it as a draft.

## Normative: Add Locale.prototype.getVariants #960

https://github.com/tc39/ecma402/pull/960

RGN: Variants is the missing getter on locale instance. It’s a multi-valued set of subtags that can appear inside of a locale. The intl spec covers their use.They’re rare but not unheard of. So far we have not had an accessor. Manual parsing is needed for “accessing”. Biggest question: should this be an array? Or as a string directly plucked out of the locale, so anyone who wants to interact with it as an array/set needs to split.

SFC: we discussed this twice, we can review what I said there hopefully. There have been some questions from DLM about motivation. In the march meeting we invited Steven Loomis who gave some great examples. Two things we should agree on as a group: is this motivated? My position is yes. The other is the shape of this API, is it a string? An array? Another general question if this is better as a PR or as a proposal. There is enough design space to have a proposal here. The same size as EAO’s trailing zeroes proposal.

RGN: Agree. You say it’s well motivated. Me too. We should open up for objections. Having resolved that, we can resolve questions about shape, design space, proposal vs. PR. Does anyone want to record explicit support?

EAO: I think this is warranted. We do have locales with variants, those should be made available. We are already trearting the variants getting them via parsing. Adding an accessor to behaviorn that we already require to be implemented. I think returning an array is the right thing to do, especially given the other methods we have.

RGN: To clarify, the valid shape is getVariants a method which returns an array or variants which is an accessor property which returns a string. 

EAO: Prefer it to be an array

SFC: We haven’t landed the locale info getters.

EAO: We can imagine them arriving and we have agreement in this group that they ought to exist.

SFC: Main concern with the array is that equality doesn’t work. GetAvailableCalendars gets the list of CLDR calendars for a locale. I think that’s a different operation for getting the locale calendar, which is a string. Could be considered a different kind of operation.

RGN: Should we formally advance the conversation to the design space?

SFC: I’d like to hear more explicitly from DLM, who’s been most explicit about lack of motivation. EAO, do you know how DLM feels about this?

EAO: DLM doesn’t oppose. We have locales. One of the locales Firefox has is ca-Valencia so we have valid use cases.

HJS: +1 to DLM not objecting to this.

SFC: We can verify at TG1.

RGN: getVariants always returns a fresh array. It might have been suggested in the issue. I think that it would make more sense as a getter property that returns a string. I think that’s how the other subtag properties work, like basename, region script, language, calendar. Many uses could conceivable want an array (so they’d have to split) but there are other cases where they just transport the string around for comparison or construction of a related locale, so the string is more convenient. So given the mixture (sometimes string, sometimes not), combined with all other properties just being string, plus convenience of splitting into an array But I’m not uncomfortable with an array if that makes more sense.

FYT: To return array, we need an order. 

RGN: Order is already specified. Question about preservation: return literal string or canonicalized one? I prefer canonicalized one.

EAO: To echo RGN, not uncomfortable with a string variant version. The point about the other subtag all having string values is good, hadn’t considered that. I’d be fine with a string.

USA: +1

SFC: It’s a list of subtags. I was wondering what the status is of keyset and equality on that. What if that proposal moves forward? Records and tuples v2? Could we use that?

RGN: I don’t think so. That would be even more surprising than an array.

USA: Relatively risky proposal in terms of advancement.

EAO: Don’t recall, but when a locale has more than one variant subtag on it, anything that consumes that is going to consider those subtags as one thing. I haven’t interacted with locale identifiers like this. If anyone has experience, that would help.

SFC:  Good point, two use cases for multiple variants. One is for a locale with multiple modifiers. You might have ca-ES-Valencia or ca-ES-Valencia-... which is the same language with the IPA alphabet. One of the balkan languages, maybe slovenian has multiple orthographies. So you have both use cases.

USA: No one on the queue. How do we proceed? We have more support than last time. Could be good for TG1.

RGN: Process: not a good fit as a proposal, more sense as a PR. We’re considering something adjacent to what we’ve got. Seeking TG2 approval as a PR so I can put it on the agenda.

SFC: This is a new API, I propose it as a proposa;. I don’t really object, but I feel that it should be a proposal. Given we have only 2 weeks, it’s going a bit fast. A proposal that goes to stage 1 or 2 in Coruña and stage 3 later would be better than a PR that goes straight to stage 3. This is a better process for us to have discussions. We have a template repository, make an explainer, should take maybe 20 minutes.

USA: A middle ground: We’ve been speedrunning proposals. Going to stage 3 is a possibility. Nonzero chance that it could have the same result as a normative PR, if we have tests. Even if things don’t go ideally you still get stage 1 or 2.

EAO: I support this going to TG1. PRefer a PR to a proposal. But in TG1, go for stage 2.7 or 3.

RGN: I’ll prep this, and try to advance all the way to completion. We’ve already covered things in this conversation.

## Henri may wish to discuss his explainer on unit preferences.

https://github.com/mozilla/explainers/blob/main/standard-measures-en-us.md 

HJS: Lots of people are using en-US. Very common thing to do. All these Intl operations take the US as an input but this is very unusual. People use en-US but aren’t there. How can we give these peoples standard measures? Can we split into 2? Rather than a huge number of parameters. I credit SFC for the overall idea, and EAO and what this identifier could be.

HJS: 3 risks/unknowns. 1. Not been implemented and evaluated for web compatibility. 2. What system setting criteria would trigger this feature? 3. On other things, it’s easy/not controversial there’s a standard way of doing this isn’t too bad for people who are using standard stuff like meters. Date pickers are an exception. Many regions use metric but still use Sunday in the first column. Would this mechanism work for these regions? E.g. you’re in Japan so you get the same date picker in the US. As a side effect of “going metric” you’d give JP users a Monday-first calendar.

## Text directionality should maybe not fall back to LTR #100

https://github.com/tc39/proposal-intl-locale-info/issues/100

FYT: Some languages don’t use LTR or RTL. Mongolian is vertical, other symbol scripts are unknown. If we say it’s not RTL then it’s LTR. So we want get this right. PR that returns RTL if we know it’s LTR, and vice versa, otherwise return undefined. It would be a normative PR.

USA: I support the PR. It’s a good idea to use not use LTR as a fullback. I prefer null to undefined as a fallback. Null signals that something might exist but it’s neither RTL or LTR.

EAO: Any issues returning top to bottom for traditional mongolian?

FYT: We could do that.

SFC: [inaudilble]

FYT: I’m saying “undefined” because it’s literally undefined.

USA: OK. Better than “LTR”.

SFC: FYT pointed out there are 2 cases. Mongolian and “I don’t kow what to do”. Returning something other than “LTR” is good. We could add “TTB” (top to bottom). We should consult with the Unicode people what to call that and what to return. We should oly return that if it’s well defined and given to us by unicode.

FYT: It’s well defined. 

EAO: It’s in CLDR.

SFC: Given that this is well-defined, we should return all four. We should put this up in A Coruña as a PR.

FYT: What about undefined?

EAO: OK.

SFC: OK. Null also makes sense.

## Define fallback behaviour in {Calendars,Collations,HourCycles,NumberingSystems,CharacterDirection,WeekInfo}OfLocale #76

https://github.com/tc39/proposal-intl-locale-info/issues/76

## And remaining time will be used to go through the issue backlog, including open design questions involving Decimal.Amount or Measure

## Normative: Don't add default formatting to lone era #957

https://github.com/tc39/ecma402/pull/957

## Normative: Don't add default formatting to lone timeZoneName #958

https://github.com/tc39/ecma402/pull/958

### Normative: Added note about sets of locales for web browser implementations needing to not change as a result of user behaviour 

USA: This was being worked on when the Intl (?) API was being worked on. User preferences. This PR adds text to that, just a single paragraph. There was some concern from the security folks from Mozilla. DLM?

DLM: I wanted to run the text by our privacy group. No concerns about the text. So I’d be happy to see this merged.

USA: Thanks. This could be as simple as asking for consensus in this call.

EAO: In the discussion between SFC, BAN, and me at the in-person TG2 meeting last fall: the client (browser) already revealing a bunch of supported locales to the server by the Accept-Language header. Chrome team wants to change that into a dialogue type of API. Where at most two locales, default and a fallback, would be revealed, rather than a more complete list. I would argue that in most cases in a browser we end up on a page where we ask for content in a locale that all the parties know that this is the preferred locale. So calls for Intl.DTF, etc. we might use a locale on this page. But vast majority ought to use that locale. That allows for an opportunity for prioritizing, providing support directly. Support for a subset of all locales that a browser knows about, depending on users explicit or implicit choice by what’s being sent to the browser based on Accept-Language. That’s nearly the only place where we might build-in an opportunity to dynamically load a set of all locales. But this proposed language – which I don’t object to – would limit our ability to do that. So I think we don’t need to be as strict. What is required for that list to stay constant? To include the user’s selection of languages for web content, if that makes sense. This came up in a discussion earlier today. IT’s well beyond late for participating in this. Text there leaves open possibility for relaxations to be made later. This kind of dynamic data loading isn’t even possible in ICU for browsers. Not objecting to the language, but here’s a part that we can discuss either now or later when ICU dynamic data loading might be possible.

SFC: Current proposed text has evolved. It states web reality. States the principles that we intent to apply concerning loading additional locales. So the current text is a good take .It leaves open the door for additional requirements. As Henri and Daniel know, I want to evolve but also know where the goal posts are, so we can develop an equitable solution. This PR does that. This PR also reflects feedback from Dan about fingerprinting. Nothing here or in 402 goes beyond what the web browser is already doing. So I think this PR is a net improvement. This gives us flexibility to evolve the spec to support disadvantaged languages and so forth.

USA: To clarify: when this came up, the idea was to restrict more radical options in terms of dynamic loading of locale date to preserve data privacy, as tradeoff between fingerprinting and providing localization experience that the user needs. This isn’t perfect but it’s a step in codifying requirements we already know about here in this group. We could merge this. We could bring this to the next TG1 meeting to get consensus.

### Intl keep trailing zeroes

EAO: This is effectively a bug fix. Intent is to change NF.format or PluralRules.select with a numeric string input value with any trailing zeroes beyond the decimal separator, we retain those zeroes. When you call NF.format(“1.0”) you get “1.0” not “1”. Doesn’t add any other capabilities or interfaces. Changes internally how this value gets formatted. This also applies the current formatting options. E.g. formatting “1.000” with minimalFractionalDigits 2 and maximumFractionalDigits 4 you get “1.000”. But with 2 and 2, you get “1.00”. Expectation is that this should be a web-compatible change to make. Likely rare that people are using numeric strings in formatting.select. And when they do this, they probably expect to give them the value we’re talking about here. There’s an issue about possibly making a change with displayTrailingZeroes, which we have, with some allowable values. We may need to add a new option to replicate the current behavior. But if it turns out that what we propose isn’t web compatible, we can add a trailing zero display option which would enable this option with numeric string inputs. But that’s a backup that I hope we don’t need to exercise.

EAO: I don’t have spec text yet. Change would be internal, in the spec. Change what is intl mathematical value, which is currently just a number, to include a representation of trailing zeroes, if any. A couple of ways to do that. This is coming out of the JS numerics recurring call. Feedback there was generally positive. My hope is to get some co-champions, and possibly present this in A Coruña.

SFC: Thanks for championing this. I’ve kind of wanted to see this but didn’t work too much in this direction. Glad you’re taking the initiative. This change has evolved from previous changes to support e.g. more significant digits, which ended up being a web-compatible string. So this is a straightforward change to add. Once we have spec text for this, I expect intl mathematical value will be able to represent trailing zeroes. When Intl.numberformat isn’t set up correctly, then we can use this information. Instead of falling back to 3 or 6 digits, we use the string. Does that align?

EAO: Not exactly. It’s not the case that those options would override these. The value being formatted has some fraction digits. Currently we don’t include trailing digits in that. With this change, they would be included. Example: with this change, if you call NF with minimumFracitonDigits with “1.0”, you’d get “1.0” out. But the intent of the change wouldn’t change any default behaviors. If you format “1.234567”, the output includes only 3 fractional digits.But with this, we end up with the three fraction digits. IF you want more, you of course have the option.

SFC: Thanks. Good example. If a number currently has trailing digits, we may want to retain them with rounding. We may need to do a bit of iteration on the exact behavior. I’ll also want to think forward in terms of formatting a decimal and how this works. I’d like it if the infrastructure we have for this case is the same as what we need for decimals. Not a requirement, nice to have.

SFC: Other comments: I consider this basically a bug fix. We get bug reports with PluralRules and NumberFormat. So this resolves teh different. It doesn’t necessarily impacts decisions on the decimal proposal, and decimal.amount idea. Two different concerns. But this lays down a god framework. I support this and I hope others do too.

EAO: Indeed, changes made here would work for any numeric type that would have trailing zeroes.

USA: Sounds like you have support.

DLM: Just wanted to also express support.

USA: This is as good of support as you can have at this stage. Bring it to TG1.
