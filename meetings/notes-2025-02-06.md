# 2025-02-06 ECMA-402 Meeting
## Logistics
### Attendees

- Shane Carr - Google i18n (SFC), Co-Moderator
- Ujjwal Sharma - Igalia (USA), Co-Moderator
- Eemeli Aro - Mozilla (EAO)
- Yusuke Suzuki - Apple (YSZ)
- Henri Sivonen - Mozilla (HJS)
- Philip Chimento - Igalia (PFC)
- Frank Yung-Fong Tang - Google i18n, V8 (FYT)

### Standing items

- [Discussion Board](https://github.com/tc39/ecma402/projects/2)
- [Status Wiki](https://github.com/tc39/ecma402/wiki/Proposal-and-PR-Progress-Tracking) -- please update!
- [Abbreviations](https://github.com/tc39/notes/blob/master/delegates.txt)
- [MDN Tracking](https://github.com/tc39/ecma402-mdn)
- [Meeting Calendar](https://calendar.google.com/calendar/embed?src=unicode.org_nubvqveeeol570uuu7kri513vc%40group.calendar.google.com)
- [Matrix](https://matrix.to/#/#tc39-ecma402:matrix.org)

## Status Updates

### Updates from the Editors

USA: No new updates, though there are new normative and editorial PRs.

### Updates from the MessageFormat Working Group

EAO: Proposal to delay the final release to give some time for the ICU4J implementation to stabilize (?). It’s possible that the finalization would be delayed by half a year. I’d also invite SFC to comment, thanks for your participation and the issues you raised. Would you find it high risk if we weren’t able to reach conclusion on those before the CLDR 47 deadline?

SFC: All issues I brought up have clear runways and the question is just about having the necessary cycles than about any controversial technical issues.

EAO: Another aspect that has been highlighted recently has been to allow percentage formatting. I hadn’t realized that even with Intl.NumberFormat there're two distinct ways of doing this.

SFC: It was discussed on Monday and Addison might just send out a ballot regarding that.

### Updates from Implementers

https://github.com/tc39/ecma402/wiki/Proposal-and-PR-Progress-Tracking

SFC: Any updates?

YSZ: Not a particular update right now.

FYT: V8 has had a v8BreakIterator, and I am working on deprecating it. We're going to start with a warning message and then completely remove it. Currently 0.2% of page loads are using it.

SFC: I though it was blocked on line break.

FYT: The data shows it is mostly word break.

SFC: Making progress on Temporal.

### Updates from the W3C i18n Group

EAO: No news.

## Proposals and Discussion Topics

https://github.com/tc39/ecma402/projects/2

### Normative: Update String toLocale{Lower,Upper}Case to ResolveLocale with best-fit matching #956

https://github.com/tc39/ecma402/pull/956

RGN: This follows up on toLocaleLowerCase, how the behavior of the locale list is strange. This aligns it with the rest of 402 behavior. We will now perform best fit matching.

HJS: First of all, considering that I spoke about this last time, I apologize if I'm contradictory, it seems to me that this assumes that there exists locale data… for example, "en"... what implementations do is special casing txt in the UCD references tr, lt, … Last time, the use case is, "I want Turkic behavior, but my text is tt, so I will specify tt, tr." The implementations don't have data to distinguish "en" as being default data. Even for the collator, which has some locales using the root, ICU4C has data that says some languages are guaranteed to use root, but here we don't have that data. So I think this shape of API doesn't reflect the data.

RGN: …

HJS: We should stick to facts wrt what data do implementations have to work with. All we have is an English text file with the exceptions documented.

RGN: But the spec should be done in a way that can adapt to arbitrary updates to the locale data.

HJS: It seems like we’re describing “available locales” which there aren’t any for case mapping. The reality is that there’s three cases and everything else.

RGN: We’ve handled the special cases in the spec as you’d expect. Anba raised a valid point about explicit specification about an unknown locale (und) maybe ought to be deterministic. We might want to enforce that this is the way to always get the root locale. That would just be an additional step. I would like an unknown locale, say, “zzz” to fall back to the default locale which is dependent on the host environment. If someone explicitly specifies “und” should they get the root behavior?

EAO: "No" is the consensus from earlier, because we've ended up defining/understanding that "und" is short for "undefined" which does fallback. However, "zxx" would be really appropriate here as a way to trigger root locale behavior.

USA: I think so… I think allowing people to explicitly use the root locale is good for i18n.

RGN: That said, we could punt this until later.

HJS: I think the “und” discussion is not specific to this. We also have the stable formatting proposal coming up. Whether it’s spelled und or not is a more generic discussion. What made me say what I said is the comment from last week (quotes the notes from last meeting). As RGN said, the locale exceptions would be limited to the 4 we discussed here.

RGN: Based on this discussion, it wouldn’t need to. Based on availablelocaleslist it would just be the three and then it’d fall back to down the list. That really is the question here: do we want to construct the list as if there’s data for all available locales and therefore “en” would be recognized and used like a root locale and not fall down the array. I prefer the former. “en” is not an unknown locale in a way the root locale is. The issue is that anytime the list includes “tr” and “az” you’d always get that behavior and nothing above that in the list. This is observable. Do we want “I”.toLocaleLowerCase(["und", "tr"]) to be a dotless or a dotted lowercase “i”?

EAO: Please file an issue to the stable formatting repo about these operations.

SFC: This sounds like a little bit like the comment I made last month regarding text locales and formatting locales not really being the same thing. The text locale is not really derived from the user for instance. It also is very different from how it’s handled. It’s somehow U?? based than CLDR based. It’s mostly script based. We sometimes use the term “content locale”. Every language has data since if it’s in unicode then it’d have some algorithms. The way we’ve achieved this for Segmenter is that the locales the browser allows for formatting is the same that we allow for segmenter. That would be another solution perhaps: if we wanted to use for an algorithm for figuring out whether the locale data is present. That would mean that “en,tr” would then use the “en” behavior and “tt,tr” use the “tr” behavior. If some browser didn’t want to ship a smaller language in latin for instance, like Icelandic ("is"), then "is,tr" would use Turkic behavior.

HJS: The first item in the array is what matters and the rest is discarded. This won’t work for “tt, tr” and “en, tr” would have the “en” behavior. Why would someone do this then? What’s the use case? Why do we care about defining this other than for web compat? Is there a legitimate use case apart from “the web is weird”. 

RGN: …

HJS: It’s well defined in the spec but not in the wild. Maybe you can be sure that “en” would follow root. But if you go into european minority languages, Icelandic for instance is majority but talking about upper vs lower serbian, are they tested enough? Is it well defined to have an algorithm where the input is nowhere close to what we have in CLDR. The only thing we have is the special casing file.

RGN: That’s true and given the nature of it, that’s the nature of exceptions. We can put all input locales in one of three categories: (1) subject to known special casing (2) Known to the implementation but not subject to special casing, and (3) unknown to the implementation. When we are in this list context, that matters, because "unknown" falls back in the array but (1) or (2) should use the needed data.

HJS: In that case we end up with something totally bogus like in Segmenter atm. If we ask it if it knows about “fi-SE” which is something that exists in the world but not in CLDR but if you ask it in “sv-AX” which exists in the world but also in CLDR due to … reasons, because it was defined to do something specific in a way swedish from sweden doesn’t. This has nothing to do with segmentation but with date formatting. We need to take the data for a completely bogus reason. They have no vetted segmentation for this locale, no more than “fi-SE” anyway. That’s when we end up in this situation where a list of locales has nothing to do with case mapping but something else completely unrelated to it. This is unprincipled, not having anything to do with the operation under consideration.

SFC: Here's an issue where we discussed segmentation locales in CLDR.

https://unicode-org.atlassian.net/browse/CLDR-18187

We ended up deciding it’s not actually the language but the script that matters and then started thinking along those lines. For instance we had a script property for advanced breaking and such. Something similar could happen for case mapping perhaps. But I think that the principle of “does it have a special casing” is not the right question to ask. Has it been vetted is a better question to ask. This is a question that implementations might not be able to answer right now. What segmenter does is check from date formatting if it has the relevant data. We should probably figure out a way to define which locales are appropriate for case mapping.

RGN: My primary goal here is that: `"I".toLocaleLowerCase(["en", "tr"]) === "i"`, `"I".toLocaleLowerCase(["tt", "tr"]) === "ı"`. TBD: `"I".toLocaleLowerCase("und")` and `"I".toLocaleLowerCase("zxx")` in a Turkish context.

And also that the behavior as observed and specified fits in with the rest of Intl. I'm willing to modify the spec or put in notes that there is special casing for only 3 distinct languages, and adding region/script subtags ought to not affect that behavior.

SFC: I think I agree

EAO: Is the information about en and tt available anywhere? Is it information that should become available before this PR lands? In CLDR or anywhere else that one could look up some information about en, tt, or lack thereof, that would result in en,tr and tt,tr behavior?

RGN: That's really asking if CLDR has a list of known languages…

EAO: That's the likely solution, but I'm not asking specifically about CLDR. I think this is a normative PR. If we cannot implement the spec as-is… should we not ensure that the data to make the spec implementable exists first?

RGN: I'm contending that it is implementable right now given the narrowness of special casing.

HJS: Well, if you want to implement it, you need some data that gives you a different answer for en and tt. Where should the implementer get that data? And why should it be that we've put in all this energy to get a list that contains en, rather than taking the much smaller list that are known to be tr-like in case mapping. Documenting something like that simply is a better solution than this which seems to specify more than CLDR does. It seems extending the list that contains "az" and "tr" to also include "tt" and others is a shorter path to reach the goal. But going and getting the behavior for “tt” and similar languages is a better solution than the opposite. 

RGN: We’re talking about the same thing from different angles here. My goal is to get a spec while as an implementer you specifically care about the exceptions.

SFC: I think the idea is that the PR in its current state doesn’t achieve it’s goals because it achieves the wrong thing for “en,tr”. We have to have a chat upstream regarding what’s supported where, perhaps adding “tt” to this list, maybe vetting the languages here.

RGN: Two questions: special treatment for ["und", "tr"] and/or ["zxx", "tr"], or just fall back to “tr” in both cases.

SFC: I think we established last week that falling back to “tr” is correct.

RGN: Answers my question, I’m satisfied.

### Normative: Don't add default formatting to lone era or timeZoneName #957

https://github.com/tc39/ecma402/pull/957

PFC: This was last discussed in July 2020: https://github.com/tc39/ecma402/blob/main/meetings/notes-2020-07-09.md#cannot-output-only-era-or-timezonename-461

PFC: Currently if you pass "era" by itself, you get the rest of the datetime options added in by default. What I'd like to do here is adding in those default if era or timeZoneName are passed by themself. This would align with the behavior for dayPeriod.	I would update this to add formats to the list of minimum required formats as suggested by Anba.

SFC: Anba knows the spec inside out except for perhaps RGN.

PFC: Any comments?

SFC: This is the right thing to do, my only worry is web compat. `new Intl.DateTimeFormat("en", { era: "long" }).format(new Date())` is not an unreasonable thing for a developer to write. `new Intl.DateTimeFormat("en", { era: "standaloneShort" }).format(new Date())` could be a workaround.

USA: Seems like this is not technically a normative change, since we have the ability to change formatted output.

HJS: Whether the change is normative or not is not really the right question; the web compat question is the relevant thing. We know that changing the thin space caused a web compat problem. So it's not enough to say that the spec has reserved the right to change the behavior. The lines of code SFC showed seem reasonably compelling, putting a burden of proof on the proposer to prove that this won't break the web.

USA: I haven't thought of compatibility from that angle… we don't always consider this a breaking issue.

SFC: To respond to Ujjwal, the spec change shows that this is hard not to think of this as a normative change since even on the spec level we supply year and month to the `AvailableFormats` check. As much as I want this to land, the lines don’t convince me of this not being a web compat change. We thought about displaynames for the eras for example. Maybe we can explore another path to have this behavior. I could agree that just the timeZoneName change could be web compatible.

EAO: Given how in general we’re not specifying how the exact output would be, I think having this functionality would be nice.

PFC: Maybe we should split up the PR for the two and move forward with timeZoneName and do some more research for era but overall I agree with EAO’s view.

SFC: Let’s do that, we have two different changes and I think they’re definitely separate and have a bunch of differences that make them differently palatable.

HJS: I’d still suggest an HTTP archive search and demonstrate that this isn’t a problem.

SFC: Given that this is changing existing behavior that’s atleast a year old, it would be good to have evidence. If it was still stage 3, I’d be more up for the change but given that it’s been shipping, we ought to do our homework. Thanks PFC for putting in the time for this.

PFC: I’d like to pursue checking if the cleanest API is web compatible first.

SFC: Any concerns apart from the web compat issues we just discussed?

SFC: It sounds like HJS was okay with httparchive evidence?

HJS: It's best if someone implemented it first, but yeah.

SFC: Should we bring this to the TG1 meeting?

EAO: I think it needs the evidence first, and splitting the PR.

PFC: Splitting the PR, I can do it in 5 minutes. Gathering the evidence, given that the agenda deadline is tomorrow, I don't think it's realistic.

SFC: I feel like the next TG1 meeting is coming up right next. There’s two meetings in Q1 and then one more in early Q2, I think. So I think we should wait until then. Sounds good?

SFC: Sure.

### Select null locale as proposed solution & add Intl API specifics #18

https://github.com/tc39/proposal-stable-formatting/pull/18

[Slides](https://docs.google.com/presentation/d/14KQA1Gyy0reIyouHtzp5ofYRrcwRjkY6GajeknLWhg0/edit#slide=id.p)

EAO: I’ve booked an hour and would like to choose between two options. *Presents the slides*

**Do we accept the null proposal for the direction we should suggest?**

SFC: I like solution #2. I know there’s upsides and downsides but the upsides outweigh the downsides. We can collectively suggest TG1 that solution #2 is better for Internationalization. But I think ZB disliked solution #2?

EAO: ZB does have concerns regarding solution #2. I’m interpreting the silence as tacit agreement. There’s well yet time to present concerns. Now I’ll present a sketch of a solution.

**Collator: follow root collation**

**DisplayNames: don’t support zxx**

EAO: Would you have a specific preference on Intl.DisplayNames?

RGN: I don't mind having holes.

FYT: I agree

SFC: I kind-of prefer the echo-back behavior, since we already do that if the data is not available. But this is a fairly minor issue.

USA: I slightly prefer us not doing anything for displaynames, given that EAO couldn't find good use cases. If we do the echo, it might block us doing something better later on.

SFC: The use case would be testing. I want to set my app locale to zxx and be able to do things like screenshot testing.

EAO: The sketch of an API included here are not meant to positively assert that this is a hole; this is a hole we could end up filling later.

RGN: It also relates to the discussion from earlier. If a hole throws an exception, then at least it is detectable. If it doesn't, it could fall back to later entries in a requested locales list. You wouldn't want DisplayNames zxx,ru to give Russian display names.

EAO: For Durations the idea is to rely on SI units as much as possible. The challenge is that there’s no SI short identifiers for years, … and months. The rest have defined short names although they’re based on english names. For microsecond, the µ letter is used, which might be a first.

SFC: Did you consider using ISO8601 format for durations? Also there’s another similar looking character to Greek mu that is for micros.

HJS: That character is for back compat with legacy japanese encodings and we shouldn’t use it. (Later correction: The symbol code point is in ISO-8859-1 actually, so misremembered Japanese.)

RGN: I might advocate for the ISO-8601 duration format. It is standardized in a way that is useful for this.

USA: I wanted to second that format. I think it solves the issue of not having some values that are not well defined. One issue is, would this essentially make us normatively refer to ISO 8601? Because IXDTF doesn't talk about durations.

SFC: The shape should be roughly the same as you’d get from locales while the format we’re talking about doesn’t do anything close to a real-world locale. Maybe it’s not what you want for testing for instance. The timestamp format is actually much better in this regard.

EAO: The thing about the ISO8601 format is that it’s actually important for us to emit that. Do I recall that the HTML Time element, which does accept ISO 8601 duration format currently?

HJS: That's the submission format. The UI is supposed to show you a date picker or something.

SFC: Temporal gives you this string so it’s slightly incorrect to say that it isn't currently supported.

EAO: Ignores whether it’s “and” or “or” and gives you a comma or a comma and space separated list. For Intl.Locale I left it out for now. What happens when you attach subtags to “zxx” it gives you something very close to Intl.Locale. Should we give “zxx” a special treatment in this case? Can it stand in for a null locale that links with a script or a region? I don’t have any answers for this at the moment. For numberformat, the actual numeric part would match the JavaScript StrNumericLiteral grammar. For currency, I suggest for the currency to come after the number which is different from “en”. This matches the common behavior as well as other cases where the style adds a suffix.

RGN: I think StrNumericLiteral is too broad here and would need to be specified further; for example, whether this output would include an exponent part, or whether it would be a sequence of digits.

SFC: That question is answered by the formatting options. If the options include scientific notation then you use that but if they don’t then you shouldn’t. For compact I suggest we fall back to scientific notation. The idea that we output something conforming to that grammar is correct and which one it is could depend on the quantity.

EAO: For compact, currently there's an error (or not?) to format infinity, so that's a possibility as well.

SFC: You said compact was an error?

EAO: I'll get to compact behavior later.

EAO: For Unit Formatting, we need to come up with a list of short identifiers for those. The list is currently doable for the current SI units but I haven’t done it yet. If you ask for the short format, it’s possible to use universal or SI identifiers. For notation: “compact” the idea is to use the SI prefixes. These values are not currently available even if it looks like it. Everything except for 10^9 matches English for instance. Also 10^-6 you also get mu. PluralRules makes you always get “other”. For segmenter, this would need more specification. HJS has already raised this on the proposal repo.

SFC: For RelativeTimeFormat, you can use the letters defined by ISO8601 and also for DurationFormat possibly.

EAO: Leaving holes is problematic and we shouldn’t do that, based on this call.

SFC: Leaving permanent holes is not something we should do. Leaving holes to be filled later is fine but we’re not in a rush.

RGN: Encountering this locale should terminate locale matching always. Throwing on a hole seems fine but falling back isn’t.

EAO: The behavior already happens for null since that errors out but not for “zxx”.

RGN: I was going to bring that up. I found at least one platform that assigned its own handling for “zxx” with the combination of a subtag, and would be comfortable if ECMA-402 special handling were limited to a bare “zxx” with no other subtags.

RGN: Considering use of the root locale for segmentation/collation/case transformation/etc., that can be locale-independent but is *not* guaranteed to be stable and would need to be indicated as such… giving up stability is a one-way door.

HJS: I think the distinction of what RGN is saying… although the formatting part is stable, but the APIs that don't produce natural language output but instead process natural language input, those need a way to say, "don't exhibit behaviors that only apply to some particular locale." In the collation case, it's easy to characterize that as the root collation. For grapheme segmentation, it's the untailored default grapheme clusters and sentence rules. But for word segmentation, it's harder to define and the default rules don’t work for Chinese/Japanese/etc. I think it makes sense to be vaguer in that case and to make a distinction from the default rules. If you implement tailoring for languages that don’t support spacings. If you can do something that’s globally useful, you shouldn’t turn off segmentation for these exceptions.

### LocaleInfo text directionality

https://github.com/tc39/proposal-intl-locale-info/issues/90

SFC: We should make a choice in this group whether this is the behavior we want.

EAO: Have the issues that were discussed in the Dec call been addressed?

FYT: I marked it as editorial because it was just adding to the notes.

SFC: I agree because this is the behavior that we wanted.

### LocaleInfo minimalDays

https://github.com/tc39/proposal-intl-locale-info/issues/86

SFC: We discussed it both in Dec and Jan and I’ve been discussing it with CLDR. As far as weeks of the year are concerned, this operation is silly since the only locales that do this they use ISO weeks.

EAO: This one I’m pretty sure we discussed and we decided that it should be left out.

SFC: We discussed it without FYT in Jan.

HJS: My recollection also is that we discussed this in Jan and leave it out.

FYT: What does that mean?

HJS: Like, not have minimalDays in the API.

FYT: So we should remove minimalDays?

HJS: That was my understanding of the Jan meeting.

FYT: So you're proposing to reduce the scope of this Stage 3 proposal?

SFC: That is what is currently on the table

FYT: I can make that change if people think it is the right thing to do

EAO: +1

USA: The TG1 deadline is very soon.

HJS: We wanted to resolve issues filed by Anba before asking for Stage 4.

SFC: I agree it’s not ready.

FYT: Me too, let’s get those issues resolved before Stage 4.
